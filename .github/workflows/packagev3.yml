name: package_env

on:
  workflow_call:
    inputs:
      version: # the variable you can use in place of a matrix
        required: true
        type: string

jobs:
  generate_conda_packd_envs:
    name: ${{ inputs.version }} Python for Conda packed env
    runs-on: ubuntu-latest
    outputs:
      test_conda_packed_name: ${{ env.TEST_ENV_NAME }}
    env:
      TZ: America/New_York

    defaults:
      run:
        shell: bash -lvxeo pipefail {0}

    steps:
      - name: Checkout the code
        uses: actions/checkout@v4

      - name: Install Python for YAML CLI tools
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install YAML CLI tools
        run: |
          python3 -m pip install shyaml

      - name: Set env vars
        run: |
          set -vxeuo pipefail

          export REPOSITORY_NAME=${GITHUB_REPOSITORY#*/}  # just the repo, as opposed to org/repo
          echo "REPOSITORY_NAME=${REPOSITORY_NAME}" >> $GITHUB_ENV

          export DATETIME_STRING=$(date +%Y%m%d%H%M%S)
          echo "DATETIME_STRING=${DATETIME_STRING}" >> $GITHUB_ENV

          export PYTHONVER=$(echo ${{ inputs.version }} | sed 's/\.//g')
          echo "PYTHONVER=${PYTHONVER}" >> $GITHUB_ENV

          export CONDA_PACK_TEMPLATE_DIR=${HOME}/conda-pack-template
          echo "CONDA_PACK_TEMPLATE_DIR=${CONDA_PACK_TEMPLATE_DIR}" >> $GITHUB_ENV

          env_name=$(cat configs/config-py${PYTHONVER}.yml | shyaml get-value env_name)
          export CONDA_PACK_ENV_NAME=${env_name}
          echo "CONDA_PACK_ENV_NAME=${CONDA_PACK_ENV_NAME}" >> $GITHUB_ENV
  
          env | sort -u
          echo "$GITHUB_ENV"

      # - uses: conda-incubator/setup-miniconda@v3
      #   with:
      #     python-version: ${{ matrix.python-version }}
      #     # mamba-version: "*"
      #     channels: conda-forge
      #     channel-priority: strict
      #     activate-environment: packaging
      #     environment-file: envs/env-py${{ env.PYTHONVER }}.yml

      - name: Setup umamba
        uses: mamba-org/setup-micromamba@v1
        with:
          environment-file: envs/env-py${{ env.PYTHONVER }}.yml
          log-level: info

      - name: Check env
        run: |
          # For reference: https://www.gnu.org/software/bash/manual/html_node/The-Set-Builtin.html.
          conda info
          conda env list
          conda list
          pip list
          conda config --show-sources
          conda config --show
          printenv | sort
        #original line 1: set -vxeuo pipefail

      - name: Export files
        run: |
          set -vxeo pipefail

          export ARTIFACTS_DIR="$HOME/artifacts"
          echo "ARTIFACTS_DIR=${ARTIFACTS_DIR}" >> $GITHUB_ENV
          if [ ! -d "${ARTIFACTS_DIR}" ]; then
              mkdir -v -p "${ARTIFACTS_DIR}"
          fi

          # conda env export -n ${CONDA_PACK_ENV_NAME} -f ${ARTIFACTS_DIR}/${CONDA_PACK_ENV_NAME}.yml -c conda-forge --override-channels
          conda env export -f ${ARTIFACTS_DIR}/${CONDA_PACK_ENV_NAME}.yml
          # Per https://conda.github.io/conda-pack/cli.html:
          conda-pack -o ${ARTIFACTS_DIR}/${CONDA_PACK_ENV_NAME}.tar.gz --ignore-missing-files --ignore-editable-packages
          openssl sha256 ${ARTIFACTS_DIR}/${CONDA_PACK_ENV_NAME}.tar.gz > ${ARTIFACTS_DIR}/${CONDA_PACK_ENV_NAME}-sha256sum.txt
          openssl md5 ${ARTIFACTS_DIR}/${CONDA_PACK_ENV_NAME}.tar.gz > ${ARTIFACTS_DIR}/${CONDA_PACK_ENV_NAME}-md5sum.txt
          chmod -v 664 ${ARTIFACTS_DIR}/${CONDA_PACK_ENV_NAME}[.-]*

      - name: Contents of the env .yml file
        run: |
          cat ${ARTIFACTS_DIR}/${CONDA_PACK_ENV_NAME}.yml

      - name: Checksum files
        run: |
          cat ${ARTIFACTS_DIR}/*sum.txt

      # https://github.com/actions/upload-artifact
      - name: Upload artifacts for the env .yml file
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.CONDA_PACK_ENV_NAME }}.yml
          path: ${{ env.ARTIFACTS_DIR }}/${{ env.CONDA_PACK_ENV_NAME }}.yml
          retention-days: 60

      - name: Upload artifacts for branch
        if: |
          github.ref != 'refs/heads/main'
        uses: actions/upload-artifact@v4
        with:
          name: test-${{ env.CONDA_PACK_ENV_NAME }}
          path: ${{ env.ARTIFACTS_DIR }}
          retention-days: 14

      - name: passing output
        run: echo "TEST_ENV_NAME=${{ env.CONDA_PACK_ENV_NAME }}" >> $GITHUB_ENV

        #-${{ env.DATETIME_STRING }}
#      - name: Upload artifacts for release
#        if: |
#          github.ref == 'refs/heads/main'
#        uses: actions/upload-artifact@v4
#        with:
#          name: ${{ env.CONDA_PACK_ENV_NAME }}
#          path: ${{ env.ARTIFACTS_DIR }}
#          retention-days: 60
  testing_conda_artifact:
    name: ${{ matrix.repos.beamline_acronym }}-${{ inputs.version }}
    needs: generate_conda_packd_envs
    env:
      CONDA_PREFIX: home/runner/miniconda
      PROFILE_NAME: test
      REPO_URL: "https://github.com/${{matrix.repos.org}}/${{matrix.repos.repo}}"
    outputs:
      test_conda_packed_name: ${{ env.TEST_CONDA_PACKED_NAME }}
    strategy:
      fail-fast: false
      # just branch is the branch of profile_collections to clone and the profile_granch is the branch of profile_collections to clone the startup directory
      matrix:
        os: [ ubuntu-latest ]
        repos:
          - org: "NSLS-II-CSX"
            repo: "profile_collection"
            branch: "master"
            profile_branch: "master"
            beamline_acronym: "csx"
          - org: "NSLS-II-SRX"
            repo: "profile_collection"
            branch: "master"
            profile_branch: "master"
            beamline_acronym: "srx"
          - org: "NSLS-II-SIX"
            repo: "profile_collection"
            branch: "master"
            profile_branch: "master"
            beamline_acronym: "six"
          - org: "NSLS-II-HXN"
            repo: "profile_collection"
            branch: "master"
            profile_branch: "master"
            beamline_acronym: "hxn"
          - org: "NSLS-II-ISR"
            repo: "profile_analysis"
            branch: "master"
            profile_branch: "master"
            beamline_acronym: "isr"
          - org: "NSLS-II-BMD"
            repo: "profile_collection"
            branch: "master"
            profile_branch: "master"
            beamline_acronym: "bmm"
          - org: "NSLS-II-QAS"
            repo: "profile_collection"
            branch: "master"
            profile_branch: "master"
            beamline_acronym: "qas"
          - org: "NSLS-II-SST"
#            repo: "profile_collection"
#            branch: "master"
#            profile_branch: "master"
#            beamline_acronym: "sst"
##          - org: "NSLS-II-TES"
#            repo: "profile_collection"
#            branch: "master"
#            profile_branch: "master"
#            beamline_acronym: "tes"
#          - org: "NSLS-II-ISS"
#            repo: "profile_collection"
#            branch: "master"
#            profile_branch: "master"
#            beamline_acronym: "iss"
#          - org: "NSLS-II-IXS"
#            repo: "profile_collection"
#            branch: "master"
#            profile_branch: "master"
#            beamline_acronym: "ixs"
#          - org: "NSLS-II-CMS"
#            repo: "profile_collection"
#            branch: "master"
#            profile_branch: "master"
#            beamline_acronym: "cms"
#          - org: "NSLS-II-CHX"
#            repo: "profile_collection"
#            branch: "master"
#            profile_branch: "master"
#            beamline_acronym: "chx"
#          - org: "NSLS-II-SMI"
#            repo: "profile_collection"
#            branch: "master"
#            profile_branch: "master"
#            beamline_acronym: "smi"
#          - org: "NSLS-II-LIX"
#            repo: "profile_collection"
#            branch: "master"
#            profile_branch: "master"
#            beamline_acronym: "lix"
#          - org: "NSLS-II-XFP"
#            repo: "profile_collection"
#            branch: "master"
#            profile_branch: "master"
#            beamline_acronym: "xfp"
#          - org: "NSLS-II-AMX"
#            repo: "profile_collection"
#            branch: "master"
#            profile_branch: "master"
#            beamline_acronym: "amx"
#          - org: "NSLS-II-FMX"
#            repo: "profile_collection"
#            branch: "master"
#            profile_branch: "master"
#            beamline_acronym: "fmx"
#          - org: "NSLS-II-FXI"
#            repo: "profile_collection"
#            branch: "master"
#            profile_branch: "master"
#            beamline_acronym: "fxi"
#          - org: "NSLS-II-NYX"
#            repo: "profile_collection"
#            branch: "master"
#            profile_branch: "master"
#            beamline_acronym: "nyx"
#          - org: "NSLS-II-ESM-1"
#            repo: "profile_collection"
#            branch: "master"
#            profile_branch: "master"
#            beamline_acronym: "esm1"
#          - org: "NSLS-II-HEX"
#            repo: "profile_collection"
#            branch: "master"
#            profile_branch: "master"
#            beamline_acronym: "hex"

    runs-on: ubuntu-latest
    steps:
      - run: |
          echo "${{ needs.generate_conda_packd_envs.outputs.test_conda_packed_name }}"
          echo "TEST_CONDA_PACKED_NAME=${{ needs.generate_conda_packd_envs.outputs.test_conda_packed_name }}" >> $GITHUB_ENV
      - name: Checkout Repository
        uses: actions/checkout@v4
      - name: Cloning Remote Repositories
        run: |
          mkdir "${{matrix.repos.repo}}"
          git clone -b ${{matrix.repos.branch}} "${{ env.REPO_URL }}" "${{matrix.repos.repo}}"
      - name: Configuring defaults (pyOlog, databroker, and kafka)
        run: |
          echo "pyOlog config:"
          wget https://raw.githubusercontent.com/NSLS-II/profile-collection-ci/master/configs/pyOlog.conf -O $HOME/.pyOlog.conf
          cat $HOME/.pyOlog.conf

          echo "Classic databroker v0/v1 config:"
          databroker_conf_dir="$HOME/.config/databroker"
          beamline_acronym="${BEAMLINE_ACRONYM,,}"
          databroker_bl_conf="${beamline_acronym}.yml"
          mkdir -v -p ${databroker_conf_dir}
          wget https://raw.githubusercontent.com/NSLS-II/profile-collection-ci/master/configs/databroker.yml -O ${databroker_conf_dir}/_legacy_config.yml
          cp -v ${databroker_conf_dir}/_legacy_config.yml ${databroker_conf_dir}/${databroker_bl_conf}
          cat ${databroker_conf_dir}/_legacy_config.yml
          cat ${databroker_conf_dir}/${databroker_bl_conf}

          echo "Tiled profile config:"
          tiled_profiles_dir="$HOME/.config/tiled/profiles/"
          mkdir -v -p "${tiled_profiles_dir}"
          sed 's/^  //' << EOF > "${tiled_profiles_dir}/profiles.yml"
          ${beamline_acronym:-local}:
            direct:
              authentication:
                allow_anonymous_access: true
              trees:
              - tree: databroker.mongo_normalized:Tree.from_uri
                path: /
                args:
                  uri: mongodb://localhost:27017/metadatastore-local
                  asset_registry_uri: mongodb://localhost:27017/asset-registry-local
          EOF
            cat ${tiled_profiles_dir}/profiles.yml

            echo "Kafka config:"
            sed 's/^  //' << EOF > kafka.yml
            ---
              abort_run_on_kafka_exception: false
              bootstrap_servers:
                - localhost:9092
              runengine_producer_config:
                security.protocol: PLAINTEXT
          EOF

            echo "SUDO: Placing kafka config in /etc/bluesky"
            sudo mkdir -v -p /etc/bluesky/
            sudo mv -v kafka.yml /etc/bluesky/kafka.yml
            cat /etc/bluesky/kafka.yml
      - name: Setup Ipython Test Profile
        run: |
          pip install ipython
          echo "Preparing test profile"
          rm -rfv profile_collection
            git clone "${{ env.REPO_URL }}" profile_collection
            (
              cd profile_collection
              git checkout "${{matrix.repos.profile_branch}}"
              rm -rfv ~/.ipython/profile_${{env.PROFILE_NAME}}/
              mkdir -pv ~/.ipython/profile_${{env.PROFILE_NAME}}/
              cp -rv startup ~/.ipython/profile_${{env.PROFILE_NAME}}/
            )
          ipython profile create ${{env.PROFILE_NAME}}
      - name: Downloading Conda Artifact
        uses: actions/download-artifact@v4
        with:
          name: test-${{ env.TEST_CONDA_PACKED_NAME }}
      - name: Downloading Conda YML
        uses: actions/download-artifact@v4
        with:
          name: ${{ env.TEST_CONDA_PACKED_NAME  }}.yml
      - name: Extracting, Activating and Unpacking Conda Artifact
        run: |
          mkdir -v -p "${{ env.CONDA_PREFIX }}/envs/${{ env.TEST_CONDA_PACKED_NAME }}"
          tar -xf "${{ env.TEST_CONDA_PACKED_NAME }}.tar.gz" -C "${{ env.CONDA_PREFIX }}/envs/${{ env.TEST_CONDA_PACKED_NAME }}"
          set +u
          eval "$(conda shell.bash hook)"
          conda activate "${{ env.CONDA_PREFIX }}/envs/${{ env.TEST_CONDA_PACKED_NAME }}"
          conda unpack && echo "Unpacked successfully!"
          set -u
          conda env list
      - name: Configuring Redis
        uses: supercharge/redis-github-action@1.8.0
        with:
          redis-version: latest
      - name: Configuring Mongo
        uses: supercharge/mongodb-github-action@1.11.0
        with:
          mongodb-version: '4.4'
      - name: Set Up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.11
      - name: Performing Beamline Actions
        env:
          BEAMLINE_ACRONYM: ${{matrix.repos.beamline_acronym}}
        run: |
          echo "Performing beamline-specific tasks..."
          cfg_dir="/nsls2/data/$BEAMLINE_ACRONYM/shared/config"
          if [[ ! -d "$cfg_dir" ]]; then
            sudo mkdir -v -p "$cfg_dir" ||
            (
              echo "Error: Couldn't create dir: $cfg_dir"
              exit 1
            )
          fi
      - name: Setting up Blackhole IOC
        run: |
          python3 -m pip install -U caproto
          echo | python3 -m caproto.ioc_examples.pathological.spoof_beamline &
          trap 'kill -SIGINT %1; echo exiting...' EXIT
          sudo ln -svf caproto-repeater "/bin/caRepeater"
      - name: Checking Blackhole IOC PV's
        run: |
          sudo pip install supervisor
          chmod +x supervisor/start_supervisor.sh
          supervisor/start_supervisor.sh status
  report_generation:
    needs: testing_conda_artifact
    if: |
      always() &&
      (needs.testing_conda_artifact.result == 'success' || needs.testing_conda_artifact.result == 'failure')
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      - name: Set Up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.11
      - name: Running Script To Get Job Info To md File
        env:
          MD_FILE_NAME: markdown_file
          GH_TOKEN: ${{ github.token }}
        run: |
          python3 beamline_status_to_md.py -p "${{ inputs.version }}" -a "${{ github.run_id }}" -m "$MD_FILE_NAME"
          cat "$MD_FILE_NAME.md"
          cp "$MD_FILE_NAME.md" $GITHUB_STEP_SUMMARY
  deposition:
    needs: [testing_conda_artifact, report_generation]
    runs-on: ubuntu-latest
    steps:
      - name: Putting Output Of Previous Job as Env Var
        run: |
          echo ${{ needs.testing_conda_artifact.outputs.test_conda_packed_name }}
          echo "TEST_CONDA_PACKED_NAME=${{ needs.generate_conda_packd_envs.outputs.test_conda_packed_name }}" >> $GITHUB_ENV
      - name: checkout the code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

#      - name: pip-install dependencies
#        run: |
#          python3 -m pip install requests
      - name: download artifacts v2
        env:
          WORKFLOW_IDS: "${{ github.run_id }}"
          GHA_TOKEN: ${{github.token}}
          GH_TOKEN: ${{github.token}}
        run: |
          set -vxeuo pipefail
          python3 parse_for_artifacts.py -a "$WORKFLOW_IDS"
          ls
          pwd
#      - name: Upload artifacts to Zenodo
#        run: |
#          python3 upload-artifacts.py
      - name: Activate IPython Profile
        run: |

          for tiled_profile_name in nsls2 ${{matrix.repos.beamline_acronym}}; do
            tiled profile create --name $tiled_profile_name https://127.0.0.1:8000
          done

          set -euo pipefail
          eval "$(conda shell.bash hook)"
          conda activate "${{ env.CONDA_PREFIX }}/envs/${{ env.TEST_CONDA_PACKED_NAME }}"
          ipython --profile ${{env.PROFILE_NAME}}


#   After this compile a report for the previous job and use annotations gh
#   After that do deposition stuff